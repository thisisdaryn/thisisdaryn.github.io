<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>More inference</title>
    <meta charset="utf-8" />
    <meta name="author" content="BIDA 6001: Data Analytic Methods Using R" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# More inference
### BIDA 6001: Data Analytic Methods Using R
### last updated: 2019-11-12

---






### Steps in doing a significance test

  * State the null hypothesis, `\(H_{0}\)`
  * State the alternative hypothesis, `\(H_{1}\)`
  * Determine the critical value based on: 
    * the confidence level 
    * the alternative hypothesis: one-sided or two-sided
  * Calculate the test statistic
  * Compare the test statistic to the critical value
  * Reject or fail to reject the null hypothesis based on the comparison 
  

---
### What about one-sided test?

* Sometimes we choose to do a one-sided test. 

* Strong reason to believe that the effect is in one particular direction

* In this case, the alternative hypothesis may contain a strict inequality, e.g.
  * `\(H_{1}: \mu &gt; 0\)` 
  * `\(H_{1}: \mu &lt; 0\)`
  
* Gives some more margin for rejecting the null as the critical value becomes smaller

* You have to decide to use a 1-sided test before collecting or looking at the data

* Principle of equipoise generally goes against 1-sided tests. So use them judiciously.


  

---
### Two types of errors

* Type 1 error: rejecting the null hypothesis when it is true
  * Type 1 error rate, `\(\alpha\)`

* Type 2 error: accepting the null hypothesis when it is false
  * Type 2 error rate, `\(\beta\)`
  * Power of a study = 1 - `\(\beta\)` 
  





---
### Statistical Inference for `\((\mu_{1} - \mu_{2})\)`

#### Are the means of two independent populations the same? 


Case 1: 
`\({\sigma_{1}}^2\)` and `\({\sigma_{2}}^2\)` unknown, but assumed to be unequal, `\(n_{1} \geq 30\)` and `\(n_{2} \geq 30\)`

`$$Z = \frac{\bar{X_{1}} - \bar{X_{2}}}{\sqrt{ \frac{s_1^2}{n_{1}} + \frac{s_2^2}{n_{2}}   }} $$`


`$$ \mbox{CI:} \left( \bar{X_{1}} - \bar{X_{2}}\right) \pm Z_{1 - {(\frac{\alpha}{2})}} \sqrt{\frac{{s_1}^2}{n_1} + \frac{{s_2}^2}{n_2} }$$`


--

Case 2: 
`\({\sigma_{1}}^2\)` and `\({\sigma_{2}}^2\)` unknown, but assumed to be unequal, `\(n_{1} &lt; 30\)` and `\(n_{2} &lt; 30\)`
`$$t = \frac{\bar{X_{1}} - \bar{X_{2}}}{\sqrt{ \frac{{s_1^2}}{n_{1}} + \frac{{s_2^2}}{n_{2}}   }} $$`


`$$ \mbox{CI:} \left( \bar{X_{1}} - \bar{X_{2}}\right) \pm t_{1 - {(\frac{\alpha}{2})}} \sqrt{\frac{{s_1^2}}{n_1} + \frac{{s_2^2}}{n_2} }$$`



---
### Testing for equality of variances

  * Take the ratio of the two sample **variances**

--

  * If the ratio is between 0.5 and 2, we consider them to be close enough to equal 

---
### Paired data 

--

Case 1: `\(n \geq 30\)`
`$$Z = \frac{\bar{X_{d}} - \mu_{d}}{{\frac{s_{d}}{\sqrt{n}}}} $$`
   

`$$ \mbox{CI:} \bar{X_{d}} \pm  Z_{1 - {\frac{\alpha}{2}} } \frac{s_{d}}{\sqrt{n}} $$`


--


Case 2: `\(n &lt; 30\)` 
`$$t = \frac{\bar{X_{d}} - \mu_{d}}{{\frac{s_{d}}{\sqrt{n}}}} $$`
   

`$$ \mbox{CI:    } \bar{X_{d}} \pm  t_{1 - {\frac{\alpha}{2}} } \frac{s_{d}}{\sqrt{n}} $$`

`$$ df = n - 1$$`


    
    
    
    
---
### Means of multiple groups


  * Sometimes we want to test if the means of more than 2 groups are equal

  * Common method: ANOVA (Analysis of Variance)
    * A generalisation of the t-test
    * Retain statistical power as the number of groups gets larger better than the t-test does   
  
  * Based on comparing the variability of the group means to the overall variability among the groups




---
### Illustration with 6 groups 


&lt;img src="images/ANOVAIMage.png" width="2795" style="display: block; margin: auto;" /&gt;


---
### General idea

#### If the variability between the groups is large (their means are relatively widely dispersed) and the variability within the groups is small then we reject the null hypothesis that the groups have the same mean.


---
### Doing an ANOVA for k groups

Test Statistic 

`$$ F = \frac{MSG}{MSE} $$`


MSE (Mean square error): Measures the variability within the groups 

`$$ MSE = \displaystyle\sum\limits_{j=1}^{k} \frac{{s_i}^2}{k} = \frac{{s_1}^2 + {s_2}^2 + \cdots  {s_k}^2  }{ k }$$`

`$$df = n - k $$`

--

MSG (Mean square between groups):  measures the variance of the sample means 

`$$ MSG = n\cdot s_{\bar{X{i}}} = \displaystyle\sum\limits_{j=1}^{k} \frac{ \bar{Xj} - \bar{X} }{ k - 1} $$`

`$$ df = k -1 $$`




---
### Using ANOVA in R 

Doing an ANOVA test in R, uses the &lt;tt&gt;aov&lt;/tt&gt; command. 

Example using the entire &lt;tt&gt;flights&lt;/tt&gt; data set


```r
library(nycflights13)
my_test = aov(dep_delay~origin, data=flights)
summary(my_test)
```

```
##                 Df    Sum Sq Mean Sq F value Pr(&gt;F)    
## origin           2   1280515  640258   396.9 &lt;2e-16 ***
## Residuals   328518 529886717    1613                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 8255 observations deleted due to missingness
```

This p-value is really small so we reject the null hypothesis that the average delay is the same at all 3 airports. 





---
### Beginning inference with categorical data


Several different cases:

  * Inference on 1 variable with 2 levels (success/failure, event/no event)
    * Can use inference on proportions 
  
  * Inference on 1 variable with more than 2 levels
    * We use `\(\chi^{2}\)` Goodness of fit tests 
    
  * Inference on 2 categorical variables
    * We use `\(\chi^{2}\)` test of independence






---
### CLT for proportions

`$$ \hat{p} \sim N\left(p, \sqrt{ \frac{p(1-p)}{n} } \right)$$`




#### Note that proportions have to be between 0 and 1 




---
### Confidence Interval for proportions: 


`$$ \hat{p} \pm  Z_{1 - {\frac{\alpha}{2}} } \sqrt{ \frac{\hat{p}(1-\hat{p})}{n}}  $$`


---
### Question (openintro Page 216)

 Some people claim that they can tell the difference between a diet soda and a regular soda in the first sip. A researcher wanting to test this claim randomly sampled 80 such people. He then filled 80 plain white cups with soda, half diet and half regular through random assignment, and asked each person to take one sip from their cup and identify the soda as diet or regular. 53 participants correctly identified the soda.

* Do these data provide strong evidence that these people are any better or worse than random guessing at telling the difference between diet and regular soda?

* Interpret the p-value in this context


---
### Inference for the difference of two populations


#### Is a certain trait more common in one population than the other

* test statistic 
`$$ Z = \frac{  \hat{p_1}  - \hat{p_2}} {\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{ 1}{n_1 }  + \frac{ 1}{ n_2 }
\right)    }   }  $$`


* Confidence Interval
`$$ (\hat{p_1} - \hat{p_2}) \pm Z_{1 - {\frac{\alpha}{2}} } \frac{  \hat{p_1}  - \hat{p_2}} {\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{ 1}{n_1 }  + \frac{ 1}{ n_2 }
\right)    }   }  $$`




---
### Question (openintro Page 226)
A survey asked 827 randomly sampled registered voters in California “Do you support? Or do you oppose? Drilling for oil and natural gas off the Coast of California? Or do you not know enough to say?” Below is the distribution of responses, separated based on whether or not the respondent graduated from college.


.center[

  | not a college grad | college grad
------------- | -------------
Support |    154  | 132 
Oppose  |     180 | 126  
Do not know |  104    | 131
]

* What percent of college graduates and what percent of the non-college graduates in this sample do not know enough to have an opinion on drilling for oil and natural gas off the Coast of California?


* Conduct a hypothesis test to determine if the data provide strong evidence that the proportion of college graduates who do not have an opinion on this issue is different than that of non-college graduates.


---
### `\(\chi^2\)` Tests

  * Goodness of fit test:
    * used with one categorical variable with more than 2 levels
    
  * Test of independence:
    * to test independence of two categorical variables
    
    
  * General calculation of `\(\chi^{2}\)` test statistic:
    
`$$ \chi^2 = \sum \frac{(O - E) ^2 }{E} $$`



---
### `\(\chi^2\)` Goodness of fit tests

In this scenario:
  * there is one variable with multiple levels
  * we are testing an observed frequency table against a postulated distribution
  


---
### Example: 


Testing whether there is discrimination in jury selection among a given population (from openintro)


.center[

  | White | Black | Hispanic | Other | Total|
------------- | -------------
Jurors  | 205 | 26| 25 | 19 | 275 | 
Registered voters  | 0.72 | 0.07 | 0.12 | 0.09 | 1.00 |
]


#### Is there evidence that the jury selection process is biased?

We will test at the `\(\alpha=.05\)` level


---
### Null and alternative hypotheses

  * Null and alternative hypotheses: 
    * `\(H_{0}\)`: The jury selection process selects members of the population proportional to their race in the general population
    * `\(H_{1}\)`: The jury selection process does not select members of the population proportional to their race in the general population
    

---
### Working for problem

  * Calculating expected values based on population characteristics:
--

.center[

 Expected | White | Black | Hispanic | Other 
------------- | -------------
Jurors  | 0.72x275 = 198 | .07x275 = 19.25 | .12x275 = 33 | .09x275 = 24.75
]

--

  * Compare expected to observed
--

.center[

Jurors | White | Black | Hispanic | Other 
------------- | -------------
Expected  | 198 |  19.25 | 33 | 24.75
Observed  | 205 | 26| 25 | 19  
]

--

`$$ \chi^{2} = \frac{(198 - 205)^2}{198} + \frac{(26 - 19.25)^2}{19.25} + \frac{(25 - 33 )^2}{33} + \frac{(19 - 24.75)^2}{24.75} = 5.89 $$`


`$$ df = 4 - 1 = 3 $$` 
--

#### Critical value: 7.81, thus we do not reject the null hypothesis


---
### Assumptions for doing `\(\chi^{2}\)` tests:

  * the expected counts in each cell should be at least 5
  
  * the sample should be independent
  



---
### Working with 2 categorical variables

  *  Sometimes we want to determine if two categorical variables are independent of each other
    * Do they have any effect on each other?
    
  * We can use a `\(\chi^2\)` test of independence 
  
  * We form a contingency table of `\(R\)` rows and `\(C\)` columns corresponding to the levels of the variables
  
  * We calculate the test statistic similarly to before:
  
  `$$ \chi^2 = \sum \frac{(O - E) ^2 }{E} $$`
  
  `$$ df = (R - 1)\cdot(C - 1)$$`
  
    
---
### Openintro example (Page 241)

  * Individuals were asked to sell an item known to have malfunctioned in the past
  
  * Prospective buyers were randomized into groups to ask 3 different questions:
    * General: What can you tell me about it?
    * Positive: It doesn't have any problems, does it?
    * Negative: What problems does it have? 

  * Hypothesis
    * `\(H_{0}\)` the choice of question has no influence on whether the seller disclosed the problem
    * `\(H_{1}\)` the choice of question has a relationship

---
### Problem data

.center[

Observed | General | Positive Assumption | Negative Assumption | Total 
------------- | -------------
Disclose Problem  | 2 |  23 | 36 | 61
Hide Problem  | 71 | 50| 37 | 158
Total | 73 | 73 | 73 | 219
]

Calculating expected values:

`$$ \mbox{Expected count}_{\mbox{row i}, \mbox{column j}} = \frac{\mbox{row i total} \cdot \mbox{column j total}  } {\mbox{table total}} $$` 

---
### Working for problem

Expected Counts:
.center[

Expected counts | General | Positive Assumption | Negative Assumption | Total 
------------- | -------------
Disclose Problem  | `\(\frac{73\cdot 61}{219} = 20.33\)` |  `\(\frac{73\cdot 61}{219}= 20.33\)`  | `\(\frac{73\cdot 61}{219}= 20.33\)`  | 61
Hide Problem  | `\(\frac{73\cdot 158}{219} = 52.67\)`  | `\(\frac{73\cdot 158}{219}= 52.67\)`   | `\(\frac{73\cdot 158}{219}= 52.67\)`   | 158
Total | 73 | 73 | 73 | 219
]


Observed counts:



Observed | General | Positive Assumption | Negative Assumption | Total 
------------- | -------------
Disclose Problem  | 2 |  23 | 36 | 61
Hide Problem  | 71 | 50| 37 | 158
Total | 73 | 73 | 73 | 219



---
### Working continued


`$$ \chi^{2} = \frac{(2 - 20.33)^2}{20.33} + \frac{(23 - 20.33)^2}{20.33} + \frac{(36-20.33)^2}{20.33} $$`
`$$ + $$`
`$$ \frac{(71 - 52.67)^2}{52.67} + \frac{(50 - 52.67)^2}{52.67} + \frac{(37 - 52.67)^2}{52.67} 
 $$`
 
 
`$$ \chi^{2} = 40.13 $$`
`$$ df = (2 - 1)\cdot (3 - 1) = 2$$`

Critical value at `\(\alpha = 0.05\)`: 5.99

#### Therefore we reject the null hypothesis
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
